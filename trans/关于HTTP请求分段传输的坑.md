# 起因

最近在做百度文库的爬虫，为了逼格没有使用Curl这样现成扩展，自己用PHP造了个轮子（其实是打算在实现后，将其封装成自己的PHP工具扩展）

然后，就出现了很诡异的一幕，当页面Response的时候，会不定时的出现一些数字字母组成的字符串，800，ab00什么的。

刚开始以为是获取的时候出现了问题，把 fgets() 换成了 stream_get_line(), 貌似好了

然并软——

最后多次实验，才发现是随机出现的，有的页面是没有这样的问题的，而有的页面会随机出现……

各种google之后，发现有人说是编码问题，但是分析了下页面，发现百度文库使用的是UTF-8编码……

最后在百度中找到了自己想要的答案（虽然翻了PHP的函数文档，但是下面的回复并没有细看，结果是坑了）

# 问题

这个问题，说来简单。

HTTP 1.1协议增加了一些特性，其中就包括分段传输。

众所周知，一个http请求，响应头信息会包含content-length告诉我们body体的长度一共有多少，然后可以直接截取指定的长度。

然而，HTTP 1.1提供的这个分段传输，使用了Transfer-Encoding:chunked，而不使用content-length

使用这个方式，那自然需要告诉浏览器如何区识别什么时候读下一段，什么时候结束

SO，会出现的奇怪的字符串，就是指定下一段内容的总长度，当然，使用十六进制进行存储的。

# 解决

知道是什么问题就好解决了

## 1.使用HTTP 1.0

这个应该是最简单粗暴地方式了，因为百度文库为了浏览器兼容性考量，不可能不支持HTTP 1.0。

所以，我们只需要把协议请求头改成1.0就ok了

当然，这里会出现一个很让人不能忍的问题：我模拟的浏览器版本绝对支持1.1，如果百度做了一定的防爬虫机制，那么我可能就会被干掉-。-

## 2.过滤十六进制的内容

过滤分为两种，

### A.万能的正则表达式

通过正则表达式匹配匹配出含有十六进制分割字符串的内容，然后过滤掉

### B.效率更高的substr

通过截取\r\n的位置，然后截取内容，截断掉十六进制分割字符串
